gene1 == "NT" & gene2 == "NT" ~ "NC",
((gene1 == "NT") != (gene2 == "NT")) & (gene2_is_essential | gene1_is_essential) ~ "PC",
(gene1 != "NT" & gene2 !="NT") & (gene1 != gene2) ~ "DT",
TRUE ~ "ST")) %>%
count(target_type) %>%
mutate(study = "Parrish")
#### Ito ####
## From the paper, I took this data directly from Ito Paper.
## This is the list of essential genes and non essential genes.
#Hart_essential <- read.delim("C:/Users/Hamda/OneDrive/Documents/GitHub/PostDoc/Conway/Research/GIScoring/Ito et al/Data/Data/CEGv2.txt", stringsAsFactors = F) %>%
#  pull(GENE)
Hart_nonessential <- read.delim("C:/Users/Hamda/OneDrive/Documents/GitHub/PostDoc/Conway/Research/GIScoring/Ito et al/Data/Data/NEGv1.txt", stringsAsFactors = F) %>%
pull(Gene)
ito <- readxl::read_excel("InputData/Ito/Count_data_ParalogV1.xlsx")
ito <- ito %>%  separate(`Left-sgRNA_Right-sgRNA`, into = c("gene1_guide", "gene2_guide"), sep = "_", remove = FALSE)
ito = ito %>%
select(Aureus_gene,Pyogenes_gene) %>%
rename(gene1 = Aureus_gene, gene2 =  Pyogenes_gene  ) %>%
mutate(
gene1_is_essential = gene1 %in% common_essentials,
gene2_is_essential = gene2 %in% common_essentials
)  %>%
mutate(target_type = NA) %>%
mutate(target_type = case_when(
gene1 == "AAVS1" & gene2 == "AAVS1" ~ "NC",
((gene1 == "AAVS1") != (gene2 == "AAVS1")) & (gene2_is_essential | gene1_is_essential) ~ "PC",
(gene1 != "AAVS1" & gene2 !="AAVS1") & (gene1 != gene2) ~ "DT",
TRUE ~ "ST")) %>%
count(target_type) %>%
mutate(study = "Ito")
#### Thompson ###
# Define the file path
file_path <- "InputData/Thompson/Guide_Sequences.xlsx"
# Read the first sheet of the Excel file
guide_seq <- read_excel(file_path, sheet = 1)
thompson = read.csv("InputData/Thompson/raw_counts.txt", sep = "\t")
thompson <- thompson[seq(2, nrow(thompson), by = 2), ]
thompson = thompson %>%
select(GENE,gRNA) %>%
separate(GENE, into = c("gene1", "gene2"), sep = "_", remove = FALSE, extra = "merge") %>%
separate(gRNA, into = c("gRNA1_seq", "gRNA2_seq", "type"), sep = "_N_|_SL_oligo:", remove = FALSE, extra = "merge") %>%
select(gene1,gene2,type) %>% #,gRNA1_seq,gRNA2_seq)%>%
mutate(gene1 = ifelse(type == "Non_targt_RND_control", "Fluc", gene1)) %>%
mutate(gene2 = ifelse(type == "Non_targt_RND_control", "Fluc", gene2)) %>%
mutate(
gene1_is_essential = gene1 %in% common_essentials,
gene2_is_essential = gene2 %in% common_essentials
)  %>%
mutate(target_type = NA) %>%
mutate(target_type = case_when(
gene1 == "Fluc" & gene2 == "Fluc" ~ "NC",
((gene1 == "Fluc") != (gene2 == "Fluc")) & (gene2_is_essential | gene1_is_essential) ~ "PC",
(gene1 != "Fluc" & gene2 !="Fluc") & (gene1 != gene2) ~ "DT",
TRUE ~ "ST")) %>%
count(target_type) %>%
mutate(study = "Thompson")
################# Chymera ###
#Take Chymera data directly from the R library
chymera <- chymera_paralog
rownames(chymera) = paste0(chymera$Cas9.Guide, ";", chymera$Cpf1.Guide )
chymera = chymera %>%
filter(gene1 != "NT" & gene2 != "NT")
# Anything with "None" means its targetting the same gene twice , dont need it for now.
chymera = chymera %>%
filter (gene1 != "None" & gene2 != "None")
# positive control, this screen includes 575 genes from the pool of Core Essential Genes (CEG2) (Hart et al., 2017).
pc_genes = read_xlsx("InputData/Chymera/chymera_essential.xlsx")
pc_genes = pc_genes %>% pull(1)
chymera = chymera %>%
select(gene1, gene2) %>%
mutate(
gene1_is_essential = gene1 %in% common_essentials,
gene2_is_essential = gene2 %in% common_essentials
)  %>%
mutate(target_type = NA) %>%
mutate(target_type = case_when(
gene1 == "NegControl" & gene2 == "NegControl" ~ "NC",
((gene1 == "NegControl") != (gene2 == "NegControl")) & (gene2_is_essential | gene1_is_essential) ~ "PC",
(gene1 != "NegControl" & gene2 !="NegControl") & (gene1 != gene2) ~ "DT",
TRUE ~ "ST"))  %>%
count(target_type) %>% mutate(study = "CHyMErA")
full_data = rbind(dede, ito, thompson ,chymera, parrish)
# Calculate percentage of "PC" category per study
pc_summary <- full_data %>%
group_by(study) %>%
summarise(
total = n(),
pc_count = sum(target_type == "PC"),
pc_percent = 100 * pc_count / total
)
pc_summary
Analyse with CRIPS Common Essentials
# Analyse with CRIPS Common Essentials
common_essentials = read.csv("InputData/CRISPRInferredCommonEssentials.csv") %>%
separate(Essentials, into = c("Gene", "trash"), sep = " ") %>%
mutate(Gene = str_trim(Gene)) %>%
pull(Gene)
nc_genes = read.csv(file = "InputData/Dede/pan-species-control-nonessentials-50genes.txt", sep = "\t")
nc_genes = unname(unlist(nc_genes,recursive = TRUE))
#pc_genes = read.csv(file = "InputData/Dede/pan-species-control-essentials-50genes.txt",sep = "\t")
#pc_genes = unname(unlist(pc_genes,recursive = TRUE))
dede = read_delim("InputData/Dede/counts.txt", delim = "\t")
dede = dede %>%
select(GENE_CLONE)%>%
separate(GENE_CLONE, into = c("gene1", "gRNA1_seq",  "gene2", "gRNA2_seq"), sep = "_", remove = TRUE, extra = "merge") %>%
select(-c(gRNA1_seq,gRNA2_seq)) %>%
mutate(gene1 = ifelse(gene1 %in% nc_genes, "NT", gene1),
gene2 = if_else(gene2 %in% nc_genes, "NT", gene2))  %>%
mutate(g1_ = ifelse(gene1 < gene2, gene1, gene2),
g2_ = ifelse(gene1 < gene2, gene2, gene1)) %>%
mutate(gene1 = g1_, gene2 = g2_) %>%
select(-c(g1_, g2_)) %>%
#distinct() %>%
mutate(
gene1_is_essential = gene1 %in% common_essentials,
gene2_is_essential = gene2 %in% common_essentials
)  %>%
mutate(target_type = NA) %>%
mutate(target_type = case_when(
gene1 == "NT" & gene2 == "NT" ~ "NC",
((gene1 == "NT") != (gene2 == "NT")) & (gene2_is_essential | gene1_is_essential) ~ "PC",
(gene1 != "NT" & gene2 !="NT") & (gene1 != gene2) ~ "DT",
TRUE ~ "ST"))  %>%
count(target_type) %>% mutate(study = "Dede")
dede
328  / sum(dede$n)
328  / sum(dede$n) * 100
parrish
733 / sum(parrish$n)
733 / sum(parrish$n) * 00
733 / sum(parrish$n) * 100
ito
834 / (sum(ito$n))
834 / (sum(ito$n)) * 100
thompson
2036  / (sum(thompson$n)) * 100
chymera
full_data = rbind(dede, ito, thompson ,chymera, parrish)
pc_summary <- full_data %>%
group_by(study) %>%
summarise(
total = n(),
pc_count = sum(target_type == "PC"),
pc_percent = 100 * pc_count / total
)
pc_summary
full_data %>%
group_by(study) %>%
summarise(
total = n())
full_data
full_data %>%
group_by(study) %>%
mutate(total_guides = sum(n))
full_data %>%
group_by(study) %>%
mutate(total_guides = sum(n)) %>%
summarise(
pc_count = sum(target_type == "PC"),
pc_percent = 100 * pc_count / total_guides
)
full_data %>%
group_by(study) %>%
mutate(total_guides = sum(n)) %>%
mutate(PC_guides = count(target_type == "PC"))
full_data %>%
group_by(study) %>%
mutate(total_guides = sum(n)) %>%
filter(target_type == "PC")
full_data %>%
group_by(study) %>%
mutate(total_guides = sum(n)) %>%
filter(target_type == "PC") %>%
mutate(percentage = n/total_guides * 100)
full_data %>%
group_by(study) %>%
mutate(total_guides = sum(n)) %>%
filter(target_type == "PC") %>%
mutate(percentage = n/total_guides * 100) %>%
ggplot(aes(x = study, y = percentage)) +
geom_bar(stat = "identity", fill = "#3182bd") +
labs(
x = "Study",
y = "Percentage of 'PC' Category",
title = "Proportion of 'PC' per Study"
) +
theme_minimal() +
ylim(c(0,100))
pc_summary <- full_data %>%
group_by(study) %>%
mutate(total_guides = sum(n)) %>%
filter(target_type == "PC") %>%
mutate(percentage = n/total_guides * 100) %>%
ggplot(aes(x = study, y = percentage)) +
geom_bar(stat = "identity", fill = "#3182bd") +
labs(
x = "Study",
y = "",
title = "Percentage of guide pairs targetting atleast one common essential gene"
) +
theme_minimal() +
ylim(c(0,100))
pc_summary
# Calculate percentage of "PC" category per study
pc_summary <- full_data %>%
group_by(study) %>%
mutate(total_guides = sum(n)) %>%
filter(target_type == "PC") %>%
mutate(percentage = n/total_guides * 100) %>%
ggplot(aes(x = study, y = percentage)) +
geom_bar(stat = "identity", fill = "#3182bd") +
labs(
x = "Study",
y = "",
title = "Percentage of guide pairs targetting atleast one common essential gene"
) +
theme_minimal() +
ylim(c(0,50))
pc_summary
full_data %>%
group_by(study) %>%
mutate(total_guides = sum(n)) %>%
filter(target_type == "PC") %>%
mutate(percentage = n/total_guides * 100) %>%
ggplot(aes(x = study, y = percentage)) +
geom_bar(stat = "identity", fill = "#3182bd") +
labs(
x = "Study",
y = "",
title = "Percentage of guide pairs targetting atleast one common essential gene"
) +
theme_minimal() +
coord_flip() +
ylim(c(0,50))
library(tidyr)
library(ggplot2)
library(dplyr)
library(RColorBrewer)
library(patchwork)
library(stringr)
library(RColorBrewer)
results = read.csv("Analysis/Output/Compiled/Combined_Results.csv")
results_filtered = read.csv("Analysis/Output/Filtered/Compiled/Combined_Results.csv")
# compare AUROC of Gemini on CHYMERA before and after pre-process
filtered = results_filtered %>%
filter( Score == "Gemini(Sens)" , Cell.line == "All" )
unfiltered = results %>%
filter(Score == "Gemini(Sens)", Cell.line == "All")
custom_labeller <- function(labels) {
# Generate prefixes (a), (b), etc.
prefixes <- paste0("(", letters[seq_along(labels)] ,")\n ")
# Concatenate prefixes with original facet titles
labels <- paste0(prefixes, labels)
return(labels)
}
combine = filtered %>% inner_join(unfiltered, by = c("Metric" ,  "Score", "Cell.line", "Validation.Set", "Study.name"),
suffix = c(".filtered", ".unfiltered")) %>%
select_if(~ n_distinct(.) > 1)  %>%
pivot_longer(
cols = c(value.filtered, value.unfiltered, Common.samples.filtered, Common.samples.unfiltered, Positive.Samples.filtered, Positive.Samples.unfiltered),  # Columns to pivot
names_to = c(".value", "Time"),  # Pivoting into .value (before/after) and Time (before/after)
names_pattern = "(.*)\\.(filtered|unfiltered)",  # Regex to match and separate the column names
) %>%
mutate(Time = factor(Time, levels = c("filtered", "unfiltered"))) %>%
mutate(baseline = ifelse(Metric == "AUROC", 0.5, Positive.Samples/Common.samples))
diff = filtered %>% inner_join(unfiltered, by = c("Metric" ,  "Score", "Cell.line", "Validation.Set", "Study.name"),
suffix = c(".filtered", ".unfiltered")) %>%
select_if(~ n_distinct(.) > 1) %>%
mutate(difference =  (value.filtered - value.unfiltered) ) %>%
mutate(Validation.Set = ifelse(Validation.Set == "DepMap Hits", "De Kegel benchmark", Validation.Set)) %>%
mutate(Validation.Set = ifelse(Validation.Set == "Köferle List", "Köferle benchmark", Validation.Set)) %>%
mutate(direction = ifelse(difference < 0, "Negative", "Positive"))
plot = ggplot(diff, aes(x = Study.name, y = difference, fill = direction)) +
geom_bar(stat = "identity" ,
width = 0.6, # Narrower bars
position = position_dodge(width = 0.01) # Reducing space between bars
) +
labs(x = "Study", y = "Change", fill = "Change") +
theme_minimal(base_size = 14) +
theme(legend.position = "bottom")+
geom_hline(yintercept = 0, color = "black") +
facet_grid(cols = vars(Validation.Set), rows = vars(Metric), scales = "free_x", switch = "y",
labeller = labeller(Validation.Set = custom_labeller))+
ylim(c(-0.025,0.08))+
scale_fill_manual(
values = c("Negative" = "#D6604D", "Positive" = "#4393C3"), # Blue for positive, red for negative
name = "")+
theme(
#legend.text = element_text(size = 6), # Decrease legend text size
#legend.title = element_text(size = 7), # Decrease legend title size
#plot.subtitle = element_text(size = 7), # Adjust subtitle text size here
panel.border = element_rect(color = "darkgrey", fill = NA, size = 0.1) # Adds a border around each facet panel
) +
coord_flip()
plot
ggsave("Analysis/Figures/plots/Fig-6ab.png",plot =  plot, dpi = 600, width = 18,height = 16, units = "cm",bg = "white")
orthrus::score_combn_vs_single()
orthrus::score_combn_vs_single
?orthrus::score_combn_vs_single
rm(list = ls())
## take data directly from Orthrus manual , copy files
library(orthrus)
df <- chymera_paralog
output_folder <- file.path("Orthrus Scripts/OrthrusOutput/")
#Call the add_screens_from_table function to build up a list of screens with names
# and corresponding technical replicates, starting with T0 replicates.
sample_table <- chymera_sample_table
screens <- add_screens_from_table(sample_table)
# Add a column to indicate if gene2_gene1 exists for gene1_gene2
df_test <- df %>%
mutate(pair_exists_in_opp = paste0(gene2, "_", gene1) %in% paste0(gene1, "_", gene2)) %>%
filter(pair_exists_in_opp == TRUE) %>%
filter(!(gene1 == "NegControl" & gene2 == "NegControl"))
# Add a column to indicate if gene2_gene1 exists for gene1_gene2
df_test <- df %>%
mutate(pair_exists_in_opp = paste0(Cas9.Guide, "_", Cpf1.Guide) %in% paste0(Cpf1.Guide , "_", Cas9.Guide)) %>%
filter(pair_exists_in_opp == TRUE) %>%
filter(!(gene1 == "NegControl" & gene2 == "NegControl"))
# Now we need to normalize each screen in three different ways:
#
# To their respective T0 screens by computing log fold-changes (LFCs)
# To the respective depth of each technical replicate
# The function normalize_screens automatically performs all of these normalization steps. The function infers which columns of df need to be normalized to which T0 screens based on the normalize_name parameter of each screen in screens (screens without this optional parameter will not be normalized to other screens). Log-scaling and depth-normalization is performed on each screen regardless of the normalize_name parameter. For example, after normalization T0 columns in df will contain log-scaled, depth-normalized read counts, whereas columns from later timepoints will contain depth-normalized LFCs compared to their respective T0s.
# We do not remove any guides based on low/high read counts
df <- normalize_screens(df, screens, filter_names = c("HAP1_T0", "RPE1_T0"), min_reads = 0, max_reads = 10000)
# The last thing we need to do before scoring data is parse it into a different structure and split guides by their type, since we score dual-targeting guides separately from combinatorial-targeting guides.
#
guides <- split_guides(df, screens, "Cas9.Guide", "Cpf1.Guide")
dual <- guides[["dual"]]
single <- guides[["single"]]
paralogs <- guides[["combn"]]
screens_to_score <- c("HAP1_T12", "HAP1_T18", "RPE1_T18", "RPE1_T24")
temp <- score_combn_vs_single(paralogs, single, screens,
screens_to_score, test = "moderated-t",
return_residuals = TRUE, filter_genes = c("NT"))
temp <- score_combn_vs_single(paralogs, single, screens,
screens_to_score, test = "moderated-t",
return_residuals = TRUE, filter_genes = c("NT"))
paralogs
single
screens
temp <- score_combn_vs_single(paralogs, single, screens,
screens_to_score, test = "moderated-t",
return_residuals = TRUE, filter_genes = c("NT"))
df <- chymera_paralog
output_folder <- file.path("Orthrus Scripts/OrthrusOutput/")
#Call the add_screens_from_table function to build up a list of screens with names
# and corresponding technical replicates, starting with T0 replicates.
sample_table <- chymera_sample_table
screens <- add_screens_from_table(sample_table)
# Add a column to indicate if gene2_gene1 exists for gene1_gene2
df_test <- df %>%
mutate(pair_exists_in_opp = paste0(gene2, "_", gene1) %in% paste0(gene1, "_", gene2)) %>%
filter(pair_exists_in_opp == TRUE) %>%
filter(!(gene1 == "NegControl" & gene2 == "NegControl"))
# Add a column to indicate if gene2_gene1 exists for gene1_gene2
df_test <- df %>%
mutate(pair_exists_in_opp = paste0(Cas9.Guide, "_", Cpf1.Guide) %in% paste0(Cpf1.Guide , "_", Cas9.Guide)) %>%
filter(pair_exists_in_opp == TRUE) %>%
filter(!(gene1 == "NegControl" & gene2 == "NegControl"))
# Now we need to normalize each screen in three different ways:
#
# To their respective T0 screens by computing log fold-changes (LFCs)
# To the respective depth of each technical replicate
# The function normalize_screens automatically performs all of these normalization steps. The function infers which columns of df need to be normalized to which T0 screens based on the normalize_name parameter of each screen in screens (screens without this optional parameter will not be normalized to other screens). Log-scaling and depth-normalization is performed on each screen regardless of the normalize_name parameter. For example, after normalization T0 columns in df will contain log-scaled, depth-normalized read counts, whereas columns from later timepoints will contain depth-normalized LFCs compared to their respective T0s.
# We do not remove any guides based on low/high read counts
df <- normalize_screens(df, screens, filter_names = c("HAP1_T0", "RPE1_T0"), min_reads = 0, max_reads = 10000)
# The last thing we need to do before scoring data is parse it into a different structure and split guides by their type, since we score dual-targeting guides separately from combinatorial-targeting guides.
#
guides <- split_guides(df, screens, "Cas9.Guide", "Cpf1.Guide")
dual <- guides[["dual"]]
single <- guides[["single"]]
paralogs <- guides[["combn"]]
screens_to_score <- c("HAP1_T12", "HAP1_T18", "RPE1_T18", "RPE1_T24")
temp <- score_combn_vs_single(paralogs, single, screens,
screens_to_score, test = "moderated-t",
return_residuals = TRUE, filter_genes = c("NT"))
library(orthrus)
library(stringr)
library(dplyr)
output_folder <- file.path("Orthrus Scripts/OrthrusOutput/")
if (!dir.exists(output_folder)) { dir.create(output_folder, recursive = TRUE) }
df <- read.csv(file.path("InputData/Dede/counts.txt"), sep = "\t",
header = TRUE, stringsAsFactors = FALSE)
essentials <- read.csv(file.path("InputData/Dede/pan-species-control-essentials-50genes.txt"),
header = TRUE, stringsAsFactors = FALSE,sep = "\t")
nonessentials <- read.csv(file.path("InputData/Dede/pan-species-control-nonessentials-50genes.txt"),
header = TRUE, stringsAsFactors = FALSE,sep = "\t")
essentials <- unlist(essentials)
nonessentials <- unlist(nonessentials)
split <- str_split_fixed(df$GENE, ":", 2)
df$gene1 <- gsub("\\..*", "", split[,1])
df$gene2 <- gsub("\\..*", "", split[,2])
df$gene1[df$gene1 %in% nonessentials] <- "NegControl"
df$gene2[df$gene2 %in% nonessentials] <- "NegControl"
# Adds guide columns
split <- str_split_fixed(df$GENE_CLONE, "_", 4)
df$Guide1 <- split[,2]
df$Guide2 <- split[,4]
sample_table <- data.frame(
Screen = c("T0", "A549", "HT29", "OVCAR8"),
Replicates = c("plasmid.T0.Ex",
"A549.T2A.Ex;A549.T2B.Ex;A549.T2C.Ex",
"HT29.T2A.Ex;HT29.T2B.Ex;HT29.T2C.Ex",
"OVCAR8.T2A.Ex;OVCAR8.T2B.Ex;OVCAR8.T2C.Ex"),
NormalizeTo = c(NA, "T0", "T0", "T0")
)
batch_table <- data.frame(
Screen = c("A549", "HT29", "OVCAR8"),
Control = c("combn", "combn", "combn")
)
# Processes data
screens <- add_screens_from_table(sample_table)
# Do not filter based on min counts or max counts
df <- normalize_screens(df, screens, filter_names = "T0", min_reads = 0, max_reads = Inf)
df = df %>% select(-c("GENE_CLONE", "GENE"))
guides <- split_guides(df, screens, "Guide1", "Guide2")
dual <- guides[["dual"]]
single <- guides[["single"]]
combn <- guides[["combn"]]
screens_to_score <- c("A549", "HT29", "OVCAR8")
temp <- score_combn_vs_single(combn, single, screens,
screens_to_score, test = "moderated-t",
return_residuals = TRUE, filter_genes = c("NegControl"))
score_combn_batch(combn, single, screens, batch_table, output_folder, test = "moderated-t", loess = FALSE, filter_genes = c("NegControl"), neg_type = "Sensitizer", pos_type = "Suppressor", fdr_threshold = 0.2, differential_threshold = 0.5)
score_combn_batch
?score_combn_batch
score_combn_batch(combn, single, screens, batch_table, output_folder, test = "moderated-t", loess = FALSE, filter_genes = c("NegControl"), neg_type = "Sensitizer", pos_type = "Suppressor", fdr_threshold = 0.2, differential_threshold = 0.5, ignore_orientation = TRUE)
dual
single
temp <- score_combn_vs_single(combn, single, screens,
screens_to_score, test = "moderated-t",
return_residuals = TRUE, filter_genes = c("NegControl"))
library(orthrus)
packageVersion("orthrus")
installed.packages("orthrus")
install.packages("orthrus")
df <- chymera_paralog
df <- chymera_paralog
library(orthrus)
df <- chymera_paralog
output_folder <- file.path("Orthrus Scripts/OrthrusOutput/")
#Call the add_screens_from_table function to build up a list of screens with names
# and corresponding technical replicates, starting with T0 replicates.
sample_table <- chymera_sample_table
screens <- add_screens_from_table(sample_table)
# Add a column to indicate if gene2_gene1 exists for gene1_gene2
df_test <- df %>%
mutate(pair_exists_in_opp = paste0(gene2, "_", gene1) %in% paste0(gene1, "_", gene2)) %>%
filter(pair_exists_in_opp == TRUE) %>%
filter(!(gene1 == "NegControl" & gene2 == "NegControl"))
library(dplyr)
library(orthrus)
df <- chymera_paralog
output_folder <- file.path("Orthrus Scripts/OrthrusOutput/")
#Call the add_screens_from_table function to build up a list of screens with names
# and corresponding technical replicates, starting with T0 replicates.
sample_table <- chymera_sample_table
screens <- add_screens_from_table(sample_table)
# Add a column to indicate if gene2_gene1 exists for gene1_gene2
df_test <- df %>%
mutate(pair_exists_in_opp = paste0(gene2, "_", gene1) %in% paste0(gene1, "_", gene2)) %>%
filter(pair_exists_in_opp == TRUE) %>%
filter(!(gene1 == "NegControl" & gene2 == "NegControl"))
# Add a column to indicate if gene2_gene1 exists for gene1_gene2
df_test <- df %>%
mutate(pair_exists_in_opp = paste0(Cas9.Guide, "_", Cpf1.Guide) %in% paste0(Cpf1.Guide , "_", Cas9.Guide)) %>%
filter(pair_exists_in_opp == TRUE) %>%
filter(!(gene1 == "NegControl" & gene2 == "NegControl"))
df_test
df_test
df <- normalize_screens(df, screens, filter_names = c("HAP1_T0", "RPE1_T0"), min_reads = 0, max_reads = 10000)
# The last thing we need to do before scoring data is parse it into a different structure and split guides by their type, since we score dual-targeting guides separately from combinatorial-targeting guides.
#
guides <- split_guides(df, screens, "Cas9.Guide", "Cpf1.Guide")
dual <- guides[["dual"]]
single <- guides[["single"]]
paralogs <- guides[["combn"]]
screens_to_score <- c("HAP1_T12", "HAP1_T18", "RPE1_T18", "RPE1_T24")
temp <- score_combn_vs_single(paralogs, single, screens,
screens_to_score, test = "moderated-t",
return_residuals = TRUE, filter_genes = c("NT"))
getwd()
setwd("C:/Users/hamda/OneDrive/Documents/GitHub/PostDoc/Conway/Research/GIScoring/Benchmarking-GI-Scores/Benchmarking-GI-Scores/Orthrus Scripts")
setwd("C:/Users/hamda/OneDrive/Documents/GitHub/PostDoc/Conway/Research/GIScoring/backup/Orthrus Scripts")
setwd("C:/Users/hamda/OneDrive/Documents/GitHub/PostDoc/Conway/Research/GIScoring/backup/")
library(orthrus)
df <- chymera_paralog
output_folder <- file.path("Orthrus Scripts/OrthrusOutput/")
#Call the add_screens_from_table function to build up a list of screens with names
# and corresponding technical replicates, starting with T0 replicates.
sample_table <- chymera_sample_table
screens <- add_screens_from_table(sample_table)
# Now we need to normalize each screen in three different ways:
#
# To their respective T0 screens by computing log fold-changes (LFCs)
# To the respective depth of each technical replicate
# The function normalize_screens automatically performs all of these normalization steps. The function infers which columns of df need to be normalized to which T0 screens based on the normalize_name parameter of each screen in screens (screens without this optional parameter will not be normalized to other screens). Log-scaling and depth-normalization is performed on each screen regardless of the normalize_name parameter. For example, after normalization T0 columns in df will contain log-scaled, depth-normalized read counts, whereas columns from later timepoints will contain depth-normalized LFCs compared to their respective T0s.
# We do not remove any guides based on low/high read counts
df <- normalize_screens(df, screens, filter_names = c("HAP1_T0", "RPE1_T0"), min_reads = 0, max_reads = 10000)
# The last thing we need to do before scoring data is parse it into a different structure and split guides by their type, since we score dual-targeting guides separately from combinatorial-targeting guides.
#
guides <- split_guides(df, screens, "Cas9.Guide", "Cpf1.Guide")
dual <- guides[["dual"]]
single <- guides[["single"]]
paralogs <- guides[["combn"]]
screens_to_score <- c("HAP1_T12", "HAP1_T18", "RPE1_T18", "RPE1_T24")
temp <- score_combn_vs_single(paralogs, single, screens,
screens_to_score, test = "moderated-t",
return_residuals = TRUE, filter_genes = c("NT"))
ggsave("Analysis/Figures/plots/Figure-S1.jpeg",plot =  pc_summary,  height = 5,width = 5,dpi = 600,bg = "white",units = "cm",)
setwd("C:/Users/hamda/OneDrive/Documents/GitHub/PostDoc/Conway/Research/GIScoring/Benchmarking-GI-Scores/Benchmarking-GI-Scores/Analysis/Figures")
