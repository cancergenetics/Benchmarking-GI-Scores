{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fff356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook defines some functions that are used to calculate AUROC and AUPR for each scored screen.\n",
    "# Two benchmarks are also loaded and processed here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08391bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import scipy.cluster.hierarchy as clust\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from itertools import combinations\n",
    "from scipy.stats import ttest_rel\n",
    "from statsmodels.stats.multitest import multipletests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b2c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-define list of the scoring methods\n",
    "scores = ['zdLFC', 'Orthrus',  'Gemini(Strong)','Gemini(Sens)', 'Parrish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a7323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in each dataframe of gene pairs score and alphabetically sorts the gene pairs, such that if the A1<A2,\n",
    "# the gene pair is A1_A2, else its A2_A1\n",
    "def reindex_alphbetically(df):\n",
    "    df['gene_pair'] = df.index\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        a, b = index.split('_')\n",
    "        if a < b:\n",
    "            df.at[index, 'gene_pair'] = f'{a}_{b}'\n",
    "        else:\n",
    "            df.at[index, 'gene_pair'] = f'{b}_{a}'\n",
    "    df.set_index('gene_pair', inplace = True)     \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db8c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Jaccard similarity\n",
    "def jaccard_similarity(df, percentile):\n",
    "        \n",
    "    def keep_top_X_percent(series, percentile):\n",
    "        threshold = series.quantile(percentile)  # 95th percentile\n",
    "        #print(threshold)\n",
    "        return series.where(series >= threshold, np.nan)\n",
    "    \n",
    "    def CalculateSimilarity(set1,set2):\n",
    "        set1 = set(set1)\n",
    "        set2 = set(set2)\n",
    "        intersection = len(set1.intersection(set2))\n",
    "        union = len(set1.union(set2))\n",
    "        return intersection / union if union != 0 else np.nan\n",
    "    # Calculate pairwise Jaccard similarities\n",
    "\n",
    "    \n",
    "    df = df.apply(lambda col: keep_top_X_percent(col, percentile), axis=0)\n",
    "    #display(df)\n",
    "    # Extract non-NA indices for each column\n",
    "    non_na_indices = {col: df[df[col].notna()].index.tolist() for col in df.columns}\n",
    "    \n",
    "    # Convert dictionary to DataFrame for better viewing\n",
    "    df_indices = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in non_na_indices.items()]))\n",
    "    #display(df_indices)\n",
    "    # Create a DataFrame to store Jaccard similarities\n",
    "    columns = df_indices.columns\n",
    "    \n",
    "    jaccard_matrix = pd.DataFrame(np.nan, index=columns, columns=columns)\n",
    "\n",
    "    for col1, col2 in combinations(columns, 2):\n",
    "        \n",
    "        similarity = CalculateSimilarity(df_indices[col1], df_indices[col2])\n",
    "        jaccard_matrix.at[col1, col2] = similarity\n",
    "        jaccard_matrix.at[col2, col1] = similarity\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Fill diagonal with 1 since Jaccard similarity with itself is always 1\n",
    "    np.fill_diagonal(jaccard_matrix.values, 1)\n",
    "    return jaccard_matrix\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c37efae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_Curve(scores, labels, ground_truth, title = \"\", plot = True):\n",
    "    results = []\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(0).clf()\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label = \"random\")\n",
    "    \n",
    "    \n",
    "    for score, label in zip(scores, labels):   \n",
    "        data = { 'ground_truth': ground_truth,\n",
    "                'score': score}\n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Remove rows with NaN values in either column\n",
    "        \n",
    "        df_clean = df.dropna()\n",
    "        \n",
    "        if (df_clean.shape[0] == 0):\n",
    "            print(\"Error - All NA's here\")\n",
    "            fpr = np.nan\n",
    "            tpr = np.nan\n",
    "            auc = np.nan\n",
    "        else:\n",
    "            fpr, tpr, _ = metrics.roc_curve(df_clean['ground_truth'],  df_clean['score'])\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            \n",
    "            #create ROC curve\n",
    "            if plot:\n",
    "                plt.plot(fpr,tpr, label=label + \", auc=\"+str(auc.round(2)) + \" n=\" + str(df_clean.shape[0]))\n",
    "            \n",
    "        results.append((auc, label,df_clean.shape[0],df_clean['ground_truth'].sum()))\n",
    "    if plot:   \n",
    "        plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.5), shadow=True, ncol=2)    \n",
    "        plt.title(title)    \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "def PR_Curve(scores, labels, ground_truth, title = \"\", plot = True):\n",
    "    results = []\n",
    "    baseline = sum(ground_truth)/len(ground_truth)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(0).clf()\n",
    "        plt.ylabel('Precision')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.plot([0, 1], [baseline, baseline], color='black', lw=2, linestyle='--', label = \"baseline\")\n",
    "\n",
    "    for score, label in zip(scores, labels):    \n",
    "        data = { 'ground_truth': ground_truth,\n",
    "                'score': score}\n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Remove rows with NaN values in either column\n",
    "        df_clean = df.dropna()\n",
    "        \n",
    "\n",
    "        if (df_clean.shape[0] > 0):\n",
    "            lr_precision, lr_recall, _ = metrics.precision_recall_curve(df_clean['ground_truth'],  df_clean['score'])\n",
    "            lr_auc = metrics.auc(lr_recall, lr_precision)\n",
    "            \n",
    "                \n",
    "            if plot:   \n",
    "                plt.plot(lr_recall,lr_precision, label=label + \", auc=\"+ str(lr_auc.round(2)) + \" n=\" + str(df_clean.shape[0]))\n",
    "\n",
    "        else:\n",
    "            print(\"Error - All NA's here\")\n",
    "            lr_precision = np.nan\n",
    "            lr_recall = np.nan\n",
    "            lr_auc = np.nan\n",
    "\n",
    "\n",
    "        results.append((lr_auc, label,df_clean.shape[0],df_clean['ground_truth'].sum()))\n",
    "\n",
    "    if plot:\n",
    "        plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.5), shadow=True, ncol=2)\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each study/cell line, this function calls the ROC_Curve and PR_curve functions\n",
    "def Cell_Line_Analysis(df,cell_line_name, study_name, labels, ground_truth, plot = True):\n",
    "    \n",
    "    ground_truth.index.name = \"sorted_gene_pair\"\n",
    "\n",
    "    ground_truth = ground_truth.reset_index()\n",
    "\n",
    "    # Group by the original index and take max of ground_truth (since 1 > 0)\n",
    "    ground_truth = ground_truth.groupby('sorted_gene_pair', as_index=False).agg({'ground_truth': 'max'})\n",
    "\n",
    "    # Set index back\n",
    "    ground_truth = ground_truth.set_index('sorted_gene_pair')\n",
    "\n",
    "\n",
    "\n",
    "    df = df.join(ground_truth, how='left')\n",
    "    df = df.dropna(subset=['ground_truth'])\n",
    "\n",
    "    ground_truth = df[\"ground_truth\"]\n",
    "       \n",
    "    title = study_name + \": \" + cell_line_name\n",
    "    \n",
    "    \n",
    "    scores =  [df[column].tolist() for column in df.columns]\n",
    "    \n",
    "    roc_auc = ROC_Curve(scores, labels, ground_truth, title, plot =plot) \n",
    "    pr_auc = PR_Curve(scores, labels ,ground_truth, title, plot =plot)\n",
    "\n",
    "    return roc_auc, pr_auc, cell_line_name, study_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57c83905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in data returned by the Cell_Line_Analysis function and organises it in form of a df. \n",
    "def ConvertResultsToDF(list_of_results):\n",
    "    dfs_roc = []\n",
    "    dfs_pr = []\n",
    "\n",
    "    for result_list in list_of_results:\n",
    "        \n",
    "        roc = result_list[0]\n",
    "        pr = result_list[1]\n",
    "        cell_line = result_list[2]\n",
    "        study_name = result_list[3]\n",
    "        \n",
    "        #ROC\n",
    "        \n",
    "        roc = pd.DataFrame(roc, columns=['value', 'Score', 'Common samples', 'Positive Samples'])\n",
    "       \n",
    "        roc['Cell line'] = cell_line\n",
    "        roc['Study name'] = study_name\n",
    "\n",
    "        dfs_roc.append(roc)\n",
    "        \n",
    "        #PR\n",
    "        \n",
    "        pr = pd.DataFrame(pr, columns=['value', 'Score', 'Common samples', 'Positive Samples'])\n",
    "\n",
    "        pr['Cell line'] = cell_line\n",
    "        pr['Study name'] = study_name\n",
    "        dfs_pr.append(pr)\n",
    "        \n",
    "        \n",
    "         \n",
    "        \n",
    "    big_df_roc = pd.concat(dfs_roc, ignore_index=True)\n",
    "    big_df_pr = pd.concat(dfs_pr, ignore_index=True)\n",
    "\n",
    "    return big_df_roc, big_df_pr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a6a2332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamda\\AppData\\Local\\Temp\\ipykernel_42040\\1198573690.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ground_truth_depmap_hit = ground_truth_depmap_hit.replace({True: 1, False: 0})\n"
     ]
    }
   ],
   "source": [
    "# Load Ground truth\n",
    "# Data from 10.1016/j.cels.2021.08.006 \n",
    "barbaras = pd.read_csv('../InputData/Benchmarks/deKegel_output.csv', sep=',', index_col = 2)\n",
    "barbaras.head()\n",
    "ground_truth_depmap_hit = barbaras[['depmap_hit']]\n",
    "ground_truth_depmap_hit = ground_truth_depmap_hit.replace({True: 1, False: 0})\n",
    "ground_truth_depmap_hit = ground_truth_depmap_hit.rename(columns={'depmap_hit': 'ground_truth'})\n",
    "ground_truth_depmap_hit = ground_truth_depmap_hit.dropna()\n",
    "ground_truth_depmap_hit.to_csv('../InputData/Benchmarks/processed/ground_truth_depmap_hit_processed.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed9b499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "sorted_gene_pair",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ground_truth",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0d3455f0-f227-49fe-8595-87c9e30b9bee",
       "rows": [
        [
         "A1BG_GP6",
         "0.0"
        ],
        [
         "A1BG_IGSF1",
         "0.0"
        ],
        [
         "A1BG_KIR2DL3",
         "0.0"
        ],
        [
         "A1BG_LILRB3",
         "0.0"
        ],
        [
         "A1BG_LILRB5",
         "0.0"
        ],
        [
         "A1BG_OSCAR",
         "0.0"
        ],
        [
         "A1CF_RBM47",
         "0.0"
        ],
        [
         "A2M_A2ML1",
         "0.0"
        ],
        [
         "A2M_PZP",
         "0.0"
        ],
        [
         "A2M_A2ML1",
         "0.0"
        ],
        [
         "A2ML1_PZP",
         "0.0"
        ],
        [
         "A2ML1_CPAMD8",
         "0.0"
        ],
        [
         "AACS_ACSM2A",
         "0.0"
        ],
        [
         "AACS_ACSM4",
         "0.0"
        ],
        [
         "AADAC_AADACL3",
         "0.0"
        ],
        [
         "AADAC_NCEH1",
         "0.0"
        ],
        [
         "AADACL2_LIPE",
         "0.0"
        ],
        [
         "AADAC_AADACL3",
         "0.0"
        ],
        [
         "AADACL4_NCEH1",
         "0.0"
        ],
        [
         "AARS_AARS2",
         "0.0"
        ],
        [
         "AARS_AARS2",
         "0.0"
        ],
        [
         "AARSD1_PTGES3L",
         "0.0"
        ],
        [
         "AATK_LMTK2",
         "0.0"
        ],
        [
         "ABCA1_ABCG5",
         "0.0"
        ],
        [
         "ABCA1_ABCA3",
         "0.0"
        ],
        [
         "ABCA1_ABCA9",
         "0.0"
        ],
        [
         "ABCA1_ABCG2",
         "0.0"
        ],
        [
         "ABCA1_ABCA6",
         "0.0"
        ],
        [
         "ABCA1_ABCA4",
         "0.0"
        ],
        [
         "ABCA10_ABCA4",
         "0.0"
        ],
        [
         "ABCA10_ABCA5",
         "0.0"
        ],
        [
         "ABCA10_ABCA6",
         "0.0"
        ],
        [
         "ABCA10_ABCA7",
         "0.0"
        ],
        [
         "ABCA10_ABCA8",
         "0.0"
        ],
        [
         "ABCA10_ABCA9",
         "0.0"
        ],
        [
         "ABCA10_ABCG2",
         "0.0"
        ],
        [
         "ABCA12_ABCA3",
         "0.0"
        ],
        [
         "ABCA12_ABCA6",
         "0.0"
        ],
        [
         "ABCA12_ABCA8",
         "0.0"
        ],
        [
         "ABCA12_ABCG5",
         "0.0"
        ],
        [
         "ABCA12_ABCG2",
         "0.0"
        ],
        [
         "ABCA13_ABCA8",
         "0.0"
        ],
        [
         "ABCA13_ABCA9",
         "0.0"
        ],
        [
         "ABCA13_ABCG2",
         "0.0"
        ],
        [
         "ABCA13_ABCA4",
         "0.0"
        ],
        [
         "ABCA2_ABCG1",
         "0.0"
        ],
        [
         "ABCA2_ABCA7",
         "0.0"
        ],
        [
         "ABCA2_ABCA3",
         "0.0"
        ],
        [
         "ABCA2_ABCG8",
         "0.0"
        ],
        [
         "ABCA3_ABCA5",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 24215
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorted_gene_pair</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1BG_GP6</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1BG_IGSF1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1BG_KIR2DL3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1BG_LILRB3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1BG_LILRB5</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZSWIM4_ZSWIM5</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZER1_ZYG11A</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZER1_ZYG11B</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPP_ZYX</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUL9_ZZEF1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24215 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ground_truth\n",
       "sorted_gene_pair              \n",
       "A1BG_GP6                   0.0\n",
       "A1BG_IGSF1                 0.0\n",
       "A1BG_KIR2DL3               0.0\n",
       "A1BG_LILRB3                0.0\n",
       "A1BG_LILRB5                0.0\n",
       "...                        ...\n",
       "ZSWIM4_ZSWIM5              0.0\n",
       "ZER1_ZYG11A                0.0\n",
       "ZER1_ZYG11B                0.0\n",
       "LPP_ZYX                    0.0\n",
       "CUL9_ZZEF1                 0.0\n",
       "\n",
       "[24215 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ground Truth 2\n",
    "# Data is downloaded from : DOI: 10.1016/j.celrep.2022.110636\n",
    "\n",
    "Koferle = pd.read_excel(\"../InputData/Benchmarks/Koferle.xlsx\", sheet_name='PaCT')\n",
    "Koferle[['gene1', 'gene2']] = Koferle['Pair'].str.split('_', expand=True)\n",
    "\n",
    "# Use apply along axis=1 to reorder the gene names alphabetically and reconstruct the 'Pair'\n",
    "Koferle['Pair'] = Koferle.apply(lambda x: '_'.join(sorted([x['gene1'], x['gene2']])), axis=1)\n",
    "Koferle.rename(columns = {'Pair':'sorted_gene_pair'}, inplace = True)\n",
    "\n",
    "#display(Koferle[Koferle.duplicated('sorted_gene_pair', keep=False)])\n",
    "Koferle = Koferle[['sorted_gene_pair', 'Sub-Dataset', 'Correlation Spearman', 'Screen Type', 'Hit?']]\n",
    "Koferle.set_index('sorted_gene_pair', inplace=True)\n",
    "#Koferle\n",
    "\n",
    "Koferle = Koferle.copy()\n",
    "Koferle = Koferle[Koferle['Screen Type'] == 'AVANA']\n",
    "Koferle = Koferle[Koferle['Sub-Dataset'] == 'expr_paralog']#\n",
    "Koferle['ground_truth'] = np.nan\n",
    "Koferle.loc[(Koferle['Correlation Spearman'] > 0) & (Koferle['Hit?'] == 'yes'), ['ground_truth']] = 1\n",
    "Koferle.loc[(Koferle['Correlation Spearman'] < 0) & (Koferle['Hit?'] == 'no'), ['ground_truth']] = 0\n",
    "Koferle = Koferle.dropna(subset=['ground_truth'])\n",
    "\n",
    "Koferle = Koferle[['ground_truth']]\n",
    "display(Koferle[Koferle.index.duplicated(keep=False)])\n",
    "Koferle.to_csv('../InputData/Benchmarks/processed/ground_truth_koferle_processed.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e7fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Koferle = pd.read_csv('../InputData/Benchmarks/processed/ground_truth_koferle_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacon = pd.read_excel(\"C:\\\\Users\\\\hamda\\\\OneDrive\\\\Documents\\\\GitHub\\\\PostDoc\\\\Conway\\\\Research\\\\GIScoring\\\\Bacon\\\\data\\\\ev2.xlsx\")\n",
    "bacon.rename(columns = {'buffered_gene': 'gene1', 'buffering_gene': 'gene2'}, inplace = True)\n",
    "bacon['sorted_gene_pair'] = bacon.apply(lambda x: '_'.join(sorted([x['gene1'], x['gene2']])), axis=1)\n",
    "bacon = bacon[['sorted_gene_pair']]\n",
    "bacon['ground_truth'] = 1\n",
    "bacon = bacon.drop_duplicates()\n",
    "bacon.set_index('sorted_gene_pair', inplace=True)\n",
    "\n",
    "bacon.to_csv('../InputData/Benchmarks/processed/ground_truth_bacon_processed.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689372e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cell_Line_Analysis_bacon(df,cell_line_name, study_name, labels, ground_truth, plot = True):\n",
    "    df = df.dropna()\n",
    "    df = df.join(ground_truth, how='left')\n",
    "    \n",
    "\n",
    "    df['ground_truth'] = df['ground_truth'].fillna(0) # everything else is considered a negative\n",
    "    #display(df)\n",
    "    ground_truth = df[\"ground_truth\"]\n",
    "\n",
    "    title = study_name + \": \" + cell_line_name\n",
    "\n",
    "    scores =  [df[column].tolist() for column in df.columns]\n",
    "\n",
    "    roc_auc = ROC_Curve(scores, labels, ground_truth, title, plot =plot)\n",
    "    pr_auc = PR_Curve(scores, labels ,ground_truth, title, plot =plot)\n",
    "\n",
    "    return roc_auc, pr_auc, cell_line_name, study_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "def stratified_sample(df, label_col='ground_truths', frac=0.75, random_state=None):\n",
    "    sampled_parts = [\n",
    "        group.sample(frac=frac, random_state=random_state)\n",
    "        for _, group in df.groupby(label_col)\n",
    "    ]\n",
    "    return pd.concat(sampled_parts).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def Resampling_analysis(df,cell_line_name, study_name, labels, ground_truth, n_repeats=500, frac = 0.75, alpha = 0.05):\n",
    "    \n",
    "\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    df = df.join(ground_truth, how='left')\n",
    "    df = df.dropna(subset=['ground_truth'])\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_repeats):\n",
    "        df_sampled = stratified_sample(df, label_col='ground_truth', frac=frac, random_state=i)\n",
    "\n",
    "        ground_truth_sampled = df_sampled[\"ground_truth\"]\n",
    "        scores =  [df_sampled[column].tolist() for column in df_sampled.columns]\n",
    "\n",
    "        roc_auc = ROC_Curve(scores, labels, ground_truth_sampled, \"\", plot =False) \n",
    "        pr_auc = PR_Curve(scores, labels ,ground_truth_sampled, \"\", plot =False) \n",
    "        # Flatten into a single list\n",
    "        roc_auc = pd.DataFrame(roc_auc, columns=['AUROC', 'method','total','ground_truth'])\n",
    "        pr_auc = pd.DataFrame(pr_auc, columns=['AUPR', 'method','total','ground_truth'])\n",
    "\n",
    "        merged_df = pd.merge(roc_auc, pr_auc, on=['method','total','ground_truth'], how='inner')\n",
    "        #print(merged_df)\n",
    "\n",
    "        #flat_result = [roc_auc[0] ,roc_auc[1] , pr_auc[0] , pr_auc[1] ,cell_line_name, study_name]\n",
    "        # Collect results\n",
    "        merged_df['replicate'] = i\n",
    "        results = pd.concat([results, merged_df], ignore_index=True)\n",
    "    #display(results)\n",
    "    # Best method by mean AUROC\n",
    "    best_auroc_method = results.groupby(\"method\")[\"AUROC\"].mean().idxmax()\n",
    "    # Best method by mean AUPR\n",
    "    best_aupr_method = results.groupby(\"method\")[\"AUPR\"].mean().idxmax()\n",
    "\n",
    "\n",
    "    print(f\"Best AUROC Method: {best_auroc_method}\")\n",
    "    print(f\"Best AUPR Method: {best_aupr_method}\")\n",
    " \n",
    "\n",
    "    aupr_test = compare_methods_ttest(results, \"AUPR\", best_aupr_method,alpha=alpha)\n",
    "    auroc_test = compare_methods_ttest(results, \"AUROC\", best_auroc_method,alpha=alpha)\n",
    "\n",
    "    df = results.copy()\n",
    "    for metric in ['AUPR', 'AUROC']:\n",
    "        plt.figure()\n",
    "        for score in df['method'].unique():\n",
    "            data = df[df['method'] == score][metric].dropna()\n",
    "            if len(data) < 2:\n",
    "                continue  # Skip if not enough data\n",
    "\n",
    "            sns.kdeplot(data, label=f'Score: {score}', fill=True, alpha=0.3)\n",
    "\n",
    "        plt.title(f'KDE of {metric.upper()} by Method')\n",
    "        plt.xlabel(metric.upper())\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    return pd.DataFrame(results), aupr_test, auroc_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_methods_ttest(df, metric, best_method, alpha):\n",
    "    results = []\n",
    "\n",
    "    # Pivot table: rows = replicates, columns = methods\n",
    "    pivot = df.pivot(index=\"replicate\", columns=\"method\", values=metric)\n",
    "\n",
    "    for method in pivot.columns:\n",
    "        if method == best_method:\n",
    "            continue\n",
    "\n",
    "        x = pivot[best_method]\n",
    "        y = pivot[method]\n",
    "\n",
    "        # Paired t-test\n",
    "        stat, p = ttest_rel(x, y, nan_policy='omit')\n",
    "        results.append((method, p))\n",
    "\n",
    "    # Adjust p-values for multiple comparisons\n",
    "    methods, pvals = zip(*results)\n",
    "    fdr = multipletests(pvals, method='fdr_bh')[1]\n",
    "    bonferroni = multipletests(pvals, method='bonferroni')[1]\n",
    "    significant_bh = [adj < alpha for adj in fdr]\n",
    "    significant_bonferroni = [adj < alpha for adj in bonferroni]\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"method\": methods,\n",
    "        \"p_value\": pvals,\n",
    "        \"fdr\": fdr,\n",
    "        \"bonferroni\": bonferroni,\n",
    "        \"significant_bh\": significant_bh,\n",
    "        'signicant_bonferroni': significant_bonferroni\n",
    "\n",
    "    }).sort_values(\"fdr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
